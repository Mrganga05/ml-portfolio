# -*- coding: utf-8 -*-
"""Titanic_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18ANy2MFYeeerOOx2KFlkkBX9SpDYR1v4
"""

# Titanic classification: EDA -> preprocess -> LogisticRegression -> save
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
import joblib

plt.style.use("seaborn-v0_8")

df = sns.load_dataset('titanic')
df.shape, df.head()

df.info()
df.isnull().sum()

#Simple plots (EDA)

# target distribution
sns.countplot(x = 'survived', data = df)
plt.title('Survived count')
plt.show()

# survival by sex and pclass
sns.barplot(x = 'sex', y = 'survived', data = df)
plt.title('Survived by sex')
plt.show()

sns.barplot(x = 'pclass',  y = 'survived', data = df)
plt.title('Survived by pclass')
plt.show()

# Age distribution
sns.histplot(df['age'].dropna(), bins = 30 )
plt.title('Age distribution')
plt.show()

# Fare distribution
sns.histplot(df['fare'].dropna(), bins = 30)
plt.title('Fare distribution')
plt.show()

#Choose features
features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']
target = 'survived'
data  = df[features + [target]].copy()
data.head()

#Preprocessing pipeline

numeric_features = ['age','sibsp','parch','fare','pclass']
categorical_features = ['sex','embarked']

numerical_transfomer = Pipeline(steps =[
    ('imputer', SimpleImputer(strategy = 'median')),
    ('scaler', StandardScaler())
])

categorical_transfomer = Pipeline(steps = [
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))

])

preprocessor = ColumnTransformer(transformers=[
    ('num', numerical_transfomer, numeric_features),
    ('cat', categorical_transfomer, categorical_features )

])

#Train/test split

x = data[features]
y = data[target]

x_train, x_test, y_train, y_test = train_test_split(x, y ,test_size = 0.20, random_state = 42, stratify = y)

x_train.shape, x_test.shape, y_train.value_counts(normalize = True)

clf = Pipeline(steps = [
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter = 1000, solver = 'lbfgs'))
    ])
clf.fit(x_train, y_train)

#Evaluate on test set

y_predict = clf.predict(x_test)
y_probability = clf.predict_proba(x_test)

print('Accuracy:', accuracy_score(y_test,y_predict))
print('Precision:', precision_score(y_test,y_predict))
print('Recall:', recall_score(y_test,y_predict))
print('F1:', f1_score(y_test, y_predict))
print('\nClassification Report:\n', classification_report(y_test, y_predict))

#Confusion matrix plot

import seaborn as sns
import matplotlib.pyplot as plt
cm = confusion_matrix(y_test, y_predict)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')
plt.show()

#Cross-validation quick check

cv_scores = cross_val_score(clf, x, y, cv=5, scoring='f1')
print("5-fold CV F1 scores:", cv_scores)
print("Mean F1:", cv_scores.mean())

os.makedirs('projects/titanic', exist_ok=True)
model_path = 'projects/titanic/titanic_model.joblib'
joblib.dump(clf, model_path)
print("Saved model to:", model_path)

# load model and predict
model = joblib.load(model_path)
sample = x_test.iloc[:3]
print("Sample features:\n", sample)
print("Predictions:", model.predict(sample))
print("Probabilities:", model.predict_proba(sample))